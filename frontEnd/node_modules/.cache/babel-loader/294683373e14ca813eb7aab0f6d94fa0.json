{"ast":null,"code":"import { __assign } from \"tslib\";\nimport { invariant, InvariantError } from 'ts-invariant';\nimport { equal } from '@wry/equality';\nimport { createFragmentMap, getFragmentFromSelection, getDefaultValues, getFragmentDefinitions, getOperationDefinition, getTypenameFromResult, makeReference, isField, resultKeyNameFromField, isReference, shouldInclude, hasDirectives, cloneDeep } from \"../../utilities/index.js\";\nimport { makeProcessedFieldsMerger, fieldNameFromStoreName, storeValueIsStoreObject } from \"./helpers.js\";\n;\n\nvar StoreWriter = function () {\n  function StoreWriter(cache, reader) {\n    this.cache = cache;\n    this.reader = reader;\n  }\n\n  StoreWriter.prototype.writeToStore = function (_a) {\n    var query = _a.query,\n        result = _a.result,\n        dataId = _a.dataId,\n        store = _a.store,\n        variables = _a.variables;\n    var operationDefinition = getOperationDefinition(query);\n    var merger = makeProcessedFieldsMerger();\n    variables = __assign(__assign({}, getDefaultValues(operationDefinition)), variables);\n    var ref = this.processSelectionSet({\n      result: result || Object.create(null),\n      dataId: dataId,\n      selectionSet: operationDefinition.selectionSet,\n      mergeTree: {\n        map: new Map()\n      },\n      context: {\n        store: store,\n        written: Object.create(null),\n        merge: function (existing, incoming) {\n          return merger.merge(existing, incoming);\n        },\n        variables: variables,\n        varString: JSON.stringify(variables),\n        fragmentMap: createFragmentMap(getFragmentDefinitions(query))\n      }\n    });\n\n    if (!isReference(ref)) {\n      throw process.env.NODE_ENV === \"production\" ? new InvariantError(7) : new InvariantError(\"Could not identify object \" + JSON.stringify(result));\n    }\n\n    store.retain(ref.__ref);\n    return ref;\n  };\n\n  StoreWriter.prototype.processSelectionSet = function (_a) {\n    var _this = this;\n\n    var dataId = _a.dataId,\n        result = _a.result,\n        selectionSet = _a.selectionSet,\n        context = _a.context,\n        mergeTree = _a.mergeTree;\n    var policies = this.cache.policies;\n\n    var _b = policies.identify(result, selectionSet, context.fragmentMap),\n        id = _b[0],\n        keyObject = _b[1];\n\n    dataId = dataId || id;\n\n    if (\"string\" === typeof dataId) {\n      var sets = context.written[dataId] || (context.written[dataId] = []);\n      var ref = makeReference(dataId);\n      if (sets.indexOf(selectionSet) >= 0) return ref;\n      sets.push(selectionSet);\n\n      if (this.reader && this.reader.isFresh(result, ref, selectionSet, context)) {\n        return ref;\n      }\n    }\n\n    var incomingFields = Object.create(null);\n\n    if (keyObject) {\n      incomingFields = context.merge(incomingFields, keyObject);\n    }\n\n    var typename = dataId && policies.rootTypenamesById[dataId] || getTypenameFromResult(result, selectionSet, context.fragmentMap) || dataId && context.store.get(dataId, \"__typename\");\n\n    if (\"string\" === typeof typename) {\n      incomingFields.__typename = typename;\n    }\n\n    var workSet = new Set(selectionSet.selections);\n    workSet.forEach(function (selection) {\n      var _a;\n\n      if (!shouldInclude(selection, context.variables)) return;\n\n      if (isField(selection)) {\n        var resultFieldKey = resultKeyNameFromField(selection);\n        var value = result[resultFieldKey];\n\n        if (typeof value !== 'undefined') {\n          var storeFieldName = policies.getStoreFieldName({\n            typename: typename,\n            fieldName: selection.name.value,\n            field: selection,\n            variables: context.variables\n          });\n          var childTree = getChildMergeTree(mergeTree, storeFieldName);\n\n          var incomingValue = _this.processFieldValue(value, selection, context, childTree);\n\n          var childTypename = selection.selectionSet && context.store.getFieldValue(incomingValue, \"__typename\") || void 0;\n          var merge = policies.getMergeFunction(typename, selection.name.value, childTypename);\n\n          if (merge) {\n            childTree.info = {\n              field: selection,\n              typename: typename,\n              merge: merge\n            };\n          } else {\n            maybeRecycleChildMergeTree(mergeTree, storeFieldName);\n          }\n\n          incomingFields = context.merge(incomingFields, (_a = {}, _a[storeFieldName] = incomingValue, _a));\n        } else if (policies.usingPossibleTypes && !hasDirectives([\"defer\", \"client\"], selection)) {\n          throw process.env.NODE_ENV === \"production\" ? new InvariantError(8) : new InvariantError(\"Missing field '\" + resultFieldKey + \"' in \" + JSON.stringify(result, null, 2).substring(0, 100));\n        }\n      } else {\n        var fragment = getFragmentFromSelection(selection, context.fragmentMap);\n\n        if (fragment && policies.fragmentMatches(fragment, typename, result, context.variables)) {\n          fragment.selectionSet.selections.forEach(workSet.add, workSet);\n        }\n      }\n    });\n\n    if (\"string\" === typeof dataId) {\n      var entityRef_1 = makeReference(dataId);\n\n      if (mergeTree.map.size) {\n        incomingFields = this.applyMerges(mergeTree, entityRef_1, incomingFields, context);\n      }\n\n      if (process.env.NODE_ENV !== \"production\") {\n        var hasSelectionSet_1 = function (storeFieldName) {\n          return fieldsWithSelectionSets_1.has(fieldNameFromStoreName(storeFieldName));\n        };\n\n        var fieldsWithSelectionSets_1 = new Set();\n        workSet.forEach(function (selection) {\n          if (isField(selection) && selection.selectionSet) {\n            fieldsWithSelectionSets_1.add(selection.name.value);\n          }\n        });\n\n        var hasMergeFunction_1 = function (storeFieldName) {\n          var childTree = mergeTree.map.get(storeFieldName);\n          return Boolean(childTree && childTree.info && childTree.info.merge);\n        };\n\n        Object.keys(incomingFields).forEach(function (storeFieldName) {\n          if (hasSelectionSet_1(storeFieldName) && !hasMergeFunction_1(storeFieldName)) {\n            warnAboutDataLoss(entityRef_1, incomingFields, storeFieldName, context.store);\n          }\n        });\n      }\n\n      context.store.merge(dataId, incomingFields);\n      return entityRef_1;\n    }\n\n    return incomingFields;\n  };\n\n  StoreWriter.prototype.processFieldValue = function (value, field, context, mergeTree) {\n    var _this = this;\n\n    if (!field.selectionSet || value === null) {\n      return process.env.NODE_ENV === 'production' ? value : cloneDeep(value);\n    }\n\n    if (Array.isArray(value)) {\n      return value.map(function (item, i) {\n        var value = _this.processFieldValue(item, field, context, getChildMergeTree(mergeTree, i));\n\n        maybeRecycleChildMergeTree(mergeTree, i);\n        return value;\n      });\n    }\n\n    return this.processSelectionSet({\n      result: value,\n      selectionSet: field.selectionSet,\n      context: context,\n      mergeTree: mergeTree\n    });\n  };\n\n  StoreWriter.prototype.applyMerges = function (mergeTree, existing, incoming, context, getStorageArgs) {\n    var _a;\n\n    var _this = this;\n\n    if (mergeTree.map.size && !isReference(incoming)) {\n      var e_1 = !Array.isArray(incoming) && (isReference(existing) || storeValueIsStoreObject(existing)) ? existing : void 0;\n      var i_1 = incoming;\n\n      if (e_1 && !getStorageArgs) {\n        getStorageArgs = [isReference(e_1) ? e_1.__ref : e_1];\n      }\n\n      var changedFields_1;\n\n      var getValue_1 = function (from, name) {\n        return Array.isArray(from) ? typeof name === \"number\" ? from[name] : void 0 : context.store.getFieldValue(from, String(name));\n      };\n\n      mergeTree.map.forEach(function (childTree, storeFieldName) {\n        if (getStorageArgs) {\n          getStorageArgs.push(storeFieldName);\n        }\n\n        var eVal = getValue_1(e_1, storeFieldName);\n        var iVal = getValue_1(i_1, storeFieldName);\n\n        var aVal = _this.applyMerges(childTree, eVal, iVal, context, getStorageArgs);\n\n        if (aVal !== iVal) {\n          changedFields_1 = changedFields_1 || new Map();\n          changedFields_1.set(storeFieldName, aVal);\n        }\n\n        if (getStorageArgs) {\n          invariant(getStorageArgs.pop() === storeFieldName);\n        }\n      });\n\n      if (changedFields_1) {\n        incoming = Array.isArray(i_1) ? i_1.slice(0) : __assign({}, i_1);\n        changedFields_1.forEach(function (value, name) {\n          incoming[name] = value;\n        });\n      }\n    }\n\n    if (mergeTree.info) {\n      return this.cache.policies.runMergeFunction(existing, incoming, mergeTree.info, context, getStorageArgs && (_a = context.store).getStorage.apply(_a, getStorageArgs));\n    }\n\n    return incoming;\n  };\n\n  return StoreWriter;\n}();\n\nexport { StoreWriter };\nvar emptyMergeTreePool = [];\n\nfunction getChildMergeTree(_a, name) {\n  var map = _a.map;\n\n  if (!map.has(name)) {\n    map.set(name, emptyMergeTreePool.pop() || {\n      map: new Map()\n    });\n  }\n\n  return map.get(name);\n}\n\nfunction maybeRecycleChildMergeTree(_a, name) {\n  var map = _a.map;\n  var childTree = map.get(name);\n\n  if (childTree && !childTree.info && !childTree.map.size) {\n    emptyMergeTreePool.push(childTree);\n    map.delete(name);\n  }\n}\n\nvar warnings = new Set();\n\nfunction warnAboutDataLoss(existingRef, incomingObj, storeFieldName, store) {\n  var getChild = function (objOrRef) {\n    var child = store.getFieldValue(objOrRef, storeFieldName);\n    return typeof child === \"object\" && child;\n  };\n\n  var existing = getChild(existingRef);\n  if (!existing) return;\n  var incoming = getChild(incomingObj);\n  if (!incoming) return;\n  if (isReference(existing)) return;\n  if (equal(existing, incoming)) return;\n\n  if (Object.keys(existing).every(function (key) {\n    return store.getFieldValue(incoming, key) !== void 0;\n  })) {\n    return;\n  }\n\n  var parentType = store.getFieldValue(existingRef, \"__typename\") || store.getFieldValue(incomingObj, \"__typename\");\n  var fieldName = fieldNameFromStoreName(storeFieldName);\n  var typeDotName = parentType + \".\" + fieldName;\n  if (warnings.has(typeDotName)) return;\n  warnings.add(typeDotName);\n  var childTypenames = [];\n\n  if (!Array.isArray(existing) && !Array.isArray(incoming)) {\n    [existing, incoming].forEach(function (child) {\n      var typename = store.getFieldValue(child, \"__typename\");\n\n      if (typeof typename === \"string\" && !childTypenames.includes(typename)) {\n        childTypenames.push(typename);\n      }\n    });\n  }\n\n  process.env.NODE_ENV === \"production\" || invariant.warn(\"Cache data may be lost when replacing the \" + fieldName + \" field of a \" + parentType + \" object.\\n\\nTo address this problem (which is not a bug in Apollo Client), \" + (childTypenames.length ? \"either ensure all objects of type \" + childTypenames.join(\" and \") + \" have an ID or a custom merge function, or \" : \"\") + \"define a custom merge function for the \" + typeDotName + \" field, so InMemoryCache can safely merge these objects:\\n\\n  existing: \" + JSON.stringify(existing).slice(0, 1000) + \"\\n  incoming: \" + JSON.stringify(incoming).slice(0, 1000) + \"\\n\\nFor more information about these options, please refer to the documentation:\\n\\n  * Ensuring entity objects have IDs: https://go.apollo.dev/c/generating-unique-identifiers\\n  * Defining custom merge functions: https://go.apollo.dev/c/merging-non-normalized-objects\\n\");\n}","map":{"version":3,"mappings":";AACA,SAASA,SAAT,EAAoBC,cAApB,QAA0C,cAA1C;AACA,SAASC,KAAT,QAAsB,eAAtB;AAEA,SACEC,iBADF,EAGEC,wBAHF,EAIEC,gBAJF,EAKEC,sBALF,EAMEC,sBANF,EAOEC,qBAPF,EAQEC,aARF,EASEC,OATF,EAUEC,sBAVF,EAcEC,WAdF,EAeEC,aAfF,EAgBEC,aAhBF,EAiBEC,SAjBF,QAkBO,0BAlBP;AAqBA,SAASC,yBAAT,EAAoCC,sBAApC,EAA4DC,uBAA5D,QAA2F,cAA3F;AAYC;;AAkBD;EACE,qBACkBC,KADlB,EAEUC,MAFV,EAE8B;IADZ;IACR;EACN;;EAgBGC,qCAAP,UAAoBC,EAApB,EAMsB;QALpBC,KAAK;QACLC,MAAM;QACNC,MAAM;QACNC,KAAK;QACLC,SAAS;IAET,IAAMC,mBAAmB,GAAGrB,sBAAsB,CAACgB,KAAD,CAAlD;IACA,IAAMM,MAAM,GAAGb,yBAAyB,EAAxC;IAEAW,SAAS,yBACJtB,gBAAgB,CAACuB,mBAAD,CADZ,GAEJD,SAFI,CAAT;IAKA,IAAMG,GAAG,GAAG,KAAKC,mBAAL,CAAyB;MACnCP,MAAM,EAAEA,MAAM,IAAIQ,MAAM,CAACC,MAAP,CAAc,IAAd,CADiB;MAEnCR,MAAM,QAF6B;MAGnCS,YAAY,EAAEN,mBAAmB,CAACM,YAHC;MAInCC,SAAS,EAAE;QAAEC,GAAG,EAAE,IAAIC,GAAJ;MAAP,CAJwB;MAKnCC,OAAO,EAAE;QACPZ,KAAK,OADE;QAEPa,OAAO,EAAEP,MAAM,CAACC,MAAP,CAAc,IAAd,CAFF;QAGPO,KAAK,EAAL,UAASC,QAAT,EAAsBC,QAAtB,EAAiC;UAC/B,OAAOb,MAAM,CAACW,KAAP,CAAaC,QAAb,EAAuBC,QAAvB,CAAP;QACD,CALM;QAMPf,SAAS,WANF;QAOPgB,SAAS,EAAEC,IAAI,CAACC,SAAL,CAAelB,SAAf,CAPJ;QAQPmB,WAAW,EAAE3C,iBAAiB,CAACG,sBAAsB,CAACiB,KAAD,CAAvB;MARvB;IAL0B,CAAzB,CAAZ;;IAiBA,IAAI,CAACX,WAAW,CAACkB,GAAD,CAAhB,EAAuB;MACrB,MAAMiB,OAAI,IAAJ,CAAIC,QAAJ,KAAmB,YAAnB,GAAmB,mBAAkC,CAAlC,CAAnB,GAA8D,IAAC/C,cAAD,CAAY,qDAAZ,CAApE;IACD;;IAODyB,KAAK,CAACuB,MAAN,CAAanB,GAAG,CAACoB,KAAjB;IAEA,OAAOpB,GAAP;EACD,CA5CM;;EA8CCT,4CAAR,UAA4BC,EAA5B,EAQ6B;IAR7B;;QACEG,MAAM;QACND,MAAM;QACNU,YAAY;QACZI,OAAO;QAGPH,SAAS;IAED,YAAQ,GAAK,KAAKhB,KAAL,CAAUgC,QAAvB;;IAIF,SAAkBA,QAAQ,CAACC,QAAT,CACtB5B,MADsB,EACdU,YADc,EACAI,OAAO,CAACQ,WADR,CAAlB;IAAA,IAACO,EAAE,QAAH;IAAA,IAAKC,SAAS,QAAd;;IAKN7B,MAAM,GAAGA,MAAM,IAAI4B,EAAnB;;IAEA,IAAI,aAAa,OAAO5B,MAAxB,EAAgC;MAM9B,IAAM8B,IAAI,GAAGjB,OAAO,CAACC,OAAR,CAAgBd,MAAhB,MAA4Ba,OAAO,CAACC,OAAR,CAAgBd,MAAhB,IAA0B,EAAtD,CAAb;MACA,IAAMK,GAAG,GAAGrB,aAAa,CAACgB,MAAD,CAAzB;MACA,IAAI8B,IAAI,CAACC,OAAL,CAAatB,YAAb,KAA8B,CAAlC,EAAqC,OAAOJ,GAAP;MACrCyB,IAAI,CAACE,IAAL,CAAUvB,YAAV;;MAOA,IAAI,KAAKd,MAAL,IAAe,KAAKA,MAAL,CAAYsC,OAAZ,CACjBlC,MADiB,EAEjBM,GAFiB,EAGjBI,YAHiB,EAIjBI,OAJiB,CAAnB,EAKG;QACD,OAAOR,GAAP;MACD;IACF;;IAID,IAAI6B,cAAc,GAAgB3B,MAAM,CAACC,MAAP,CAAc,IAAd,CAAlC;;IAIA,IAAIqB,SAAJ,EAAe;MACbK,cAAc,GAAGrB,OAAO,CAACE,KAAR,CAAcmB,cAAd,EAA8BL,SAA9B,CAAjB;IACD;;IAKD,IAAMM,QAAQ,GACXnC,MAAM,IAAI0B,QAAQ,CAACU,iBAAT,CAA2BpC,MAA3B,CAAX,IACAjB,qBAAqB,CAACgB,MAAD,EAASU,YAAT,EAAuBI,OAAO,CAACQ,WAA/B,CADrB,IAECrB,MAAM,IAAIa,OAAO,CAACZ,KAAR,CAAcoC,GAAd,CAAkBrC,MAAlB,EAA0B,YAA1B,CAHb;;IAKA,IAAI,aAAa,OAAOmC,QAAxB,EAAkC;MAChCD,cAAc,CAACI,UAAf,GAA4BH,QAA5B;IACD;;IAED,IAAMI,OAAO,GAAG,IAAIC,GAAJ,CAAQ/B,YAAY,CAACgC,UAArB,CAAhB;IAEAF,OAAO,CAACG,OAAR,CAAgB,qBAAS;;;MACvB,IAAI,CAACtD,aAAa,CAACuD,SAAD,EAAY9B,OAAO,CAACX,SAApB,CAAlB,EAAkD;;MAElD,IAAIjB,OAAO,CAAC0D,SAAD,CAAX,EAAwB;QACtB,IAAMC,cAAc,GAAG1D,sBAAsB,CAACyD,SAAD,CAA7C;QACA,IAAME,KAAK,GAAG9C,MAAM,CAAC6C,cAAD,CAApB;;QAEA,IAAI,OAAOC,KAAP,KAAiB,WAArB,EAAkC;UAChC,IAAMC,cAAc,GAAGpB,QAAQ,CAACqB,iBAAT,CAA2B;YAChDZ,QAAQ,UADwC;YAEhDa,SAAS,EAAEL,SAAS,CAACM,IAAV,CAAeJ,KAFsB;YAGhDK,KAAK,EAAEP,SAHyC;YAIhDzC,SAAS,EAAEW,OAAO,CAACX;UAJ6B,CAA3B,CAAvB;UAOA,IAAMiD,SAAS,GAAGC,iBAAiB,CAAC1C,SAAD,EAAYoC,cAAZ,CAAnC;;UAEA,IAAIO,aAAa,GACfC,KAAI,CAACC,iBAAL,CAAuBV,KAAvB,EAA8BF,SAA9B,EAAyC9B,OAAzC,EAAkDsC,SAAlD,CADF;;UAGA,IAAMK,aAAa,GAAGb,SAAS,CAAClC,YAAV,IACjBI,OAAO,CAACZ,KAAR,CAAcwD,aAAd,CAAoCJ,aAApC,EAAkE,YAAlE,CADiB,IAEjB,KAAK,CAFV;UAIA,IAAMtC,KAAK,GAAGW,QAAQ,CAACgC,gBAAT,CACZvB,QADY,EAEZQ,SAAS,CAACM,IAAV,CAAeJ,KAFH,EAGZW,aAHY,CAAd;;UAMA,IAAIzC,KAAJ,EAAW;YACToC,SAAS,CAACQ,IAAV,GAAiB;cAGfT,KAAK,EAAEP,SAHQ;cAIfR,QAAQ,UAJO;cAKfpB,KAAK;YALU,CAAjB;UAOD,CARD,MAQO;YACL6C,0BAA0B,CAAClD,SAAD,EAAYoC,cAAZ,CAA1B;UACD;;UAEDZ,cAAc,GAAGrB,OAAO,CAACE,KAAR,CAAcmB,cAAd,GAA4BrC,SAC3CA,GAACiD,cAAD,IAAkBO,aADyB,IAA5B,EAAjB;QAID,CAvCD,MAuCO,IACL3B,QAAQ,CAACmC,kBAAT,IACA,CAACxE,aAAa,CAAC,CAAC,OAAD,EAAU,QAAV,CAAD,EAAsBsD,SAAtB,CAFT,EAGL;UACA,MAAMrB,OAAI,IAAJ,CAAIC,QAAJ,KACJ,YADI,GACc,mBAAc,CAAd,CADd,GAC4B,IAAQ/C,cAAR,CAC9B,oBAGAoE,cAHA,GAIF,OAJE,GAIFzB,iDALgC,CADlC;QAOD;MACF,CAvDD,MAuDO;QAEL,IAAM2C,QAAQ,GAAGnF,wBAAwB,CACvCgE,SADuC,EAEvC9B,OAAO,CAACQ,WAF+B,CAAzC;;QAKA,IAAIyC,QAAQ,IAmBRpC,QAAQ,CAACqC,eAAT,CAAyBD,QAAzB,EAAmC3B,QAAnC,EAA6CpC,MAA7C,EAAqDc,OAAO,CAACX,SAA7D,CAnBJ,EAmB6E;UAC3E4D,QAAQ,CAACrD,YAAT,CAAsBgC,UAAtB,CAAiCC,OAAjC,CAAyCH,OAAO,CAACyB,GAAjD,EAAsDzB,OAAtD;QACD;MACF;IACF,CAxFD;;IA0FA,IAAI,aAAa,OAAOvC,MAAxB,EAAgC;MAC9B,IAAMiE,WAAS,GAAGjF,aAAa,CAACgB,MAAD,CAA/B;;MAEA,IAAIU,SAAS,CAACC,GAAV,CAAcuD,IAAlB,EAAwB;QACtBhC,cAAc,GAAG,KAAKiC,WAAL,CAAiBzD,SAAjB,EAA4BuD,WAA5B,EAAuC/B,cAAvC,EAAuDrB,OAAvD,CAAjB;MACD;;MAED,IAAIS,OAAO,CAAC8C,GAAR,CAAY7C,QAAZ,KAAyB,YAA7B,EAA2C;QACzC,IAAM8C,iBAAe,GAAG,UAACvB,cAAD,EAAuB;UAC7C,gCAAuB,CAACwB,GAAxB,CAA4B9E,sBAAsB,CAACsD,cAAD,CAAlD;QAAmE,CADrE;;QAEA,IAAMyB,yBAAuB,GAAG,IAAI/B,GAAJ,EAAhC;QACAD,OAAO,CAACG,OAAR,CAAgB,qBAAS;UACvB,IAAIzD,OAAO,CAAC0D,SAAD,CAAP,IAAsBA,SAAS,CAAClC,YAApC,EAAkD;YAChD8D,yBAAuB,CAACP,GAAxB,CAA4BrB,SAAS,CAACM,IAAV,CAAeJ,KAA3C;UACD;QACF,CAJD;;QAMA,IAAM2B,kBAAgB,GAAG,UAAC1B,cAAD,EAAuB;UAC9C,IAAMK,SAAS,GAAGzC,SAAS,CAACC,GAAV,CAAc0B,GAAd,CAAkBS,cAAlB,CAAlB;UACA,OAAO2B,OAAO,CAACtB,SAAS,IAAIA,SAAS,CAACQ,IAAvB,IAA+BR,SAAS,CAACQ,IAAV,CAAe5C,KAA/C,CAAd;QACD,CAHD;;QAKAR,MAAM,CAACmE,IAAP,CAAYxC,cAAZ,EAA4BQ,OAA5B,CAAoC,0BAAc;UAKhD,IAAI2B,iBAAe,CAACvB,cAAD,CAAf,IACA,CAAC0B,kBAAgB,CAAC1B,cAAD,CADrB,EACuC;YACrC6B,iBAAiB,CACfV,WADe,EAEf/B,cAFe,EAGfY,cAHe,EAIfjC,OAAO,CAACZ,KAJO,CAAjB;UAMD;QACF,CAdD;MAeD;;MAEDY,OAAO,CAACZ,KAAR,CAAcc,KAAd,CAAoBf,MAApB,EAA4BkC,cAA5B;MAEA,OAAO+B,WAAP;IACD;;IAED,OAAO/B,cAAP;EACD,CA7MO;;EA+MAtC,0CAAR,UACEiD,KADF,EAEEK,KAFF,EAGErC,OAHF,EAIEH,SAJF,EAIsB;IAJtB;;IAME,IAAI,CAACwC,KAAK,CAACzC,YAAP,IAAuBoC,KAAK,KAAK,IAArC,EAA2C;MAIzC,OAAOvB,OAAO,CAAC8C,GAAR,CAAY7C,QAAZ,KAAyB,YAAzB,GAAwCsB,KAAxC,GAAgDvD,SAAS,CAACuD,KAAD,CAAhE;IACD;;IAED,IAAI+B,KAAK,CAACC,OAAN,CAAchC,KAAd,CAAJ,EAA0B;MACxB,OAAOA,KAAK,CAAClC,GAAN,CAAU,UAACmE,IAAD,EAAOC,CAAP,EAAQ;QACvB,IAAMlC,KAAK,GAAGS,KAAI,CAACC,iBAAL,CACZuB,IADY,EACN5B,KADM,EACCrC,OADD,EACUuC,iBAAiB,CAAC1C,SAAD,EAAYqE,CAAZ,CAD3B,CAAd;;QAEAnB,0BAA0B,CAAClD,SAAD,EAAYqE,CAAZ,CAA1B;QACA,OAAOlC,KAAP;MACD,CALM,CAAP;IAMD;;IAED,OAAO,KAAKvC,mBAAL,CAAyB;MAC9BP,MAAM,EAAE8C,KADsB;MAE9BpC,YAAY,EAAEyC,KAAK,CAACzC,YAFU;MAG9BI,OAAO,SAHuB;MAI9BH,SAAS;IAJqB,CAAzB,CAAP;EAMD,CA5BO;;EA8BAd,oCAAR,UACEc,SADF,EAEEM,QAFF,EAGEC,QAHF,EAIEJ,OAJF,EAKEmE,cALF,EAKwD;;;IALxD;;IAOE,IAAItE,SAAS,CAACC,GAAV,CAAcuD,IAAd,IAAsB,CAAC/E,WAAW,CAAC8B,QAAD,CAAtC,EAAkD;MAChD,IAAMgE,GAAC,GAIL,CAACL,KAAK,CAACC,OAAN,CAAc5D,QAAd,CAAD,KAIC9B,WAAW,CAAC6B,QAAD,CAAX,IAAyBvB,uBAAuB,CAACuB,QAAD,CAJjD,CAJ6C,GAS3CA,QAT2C,GAShC,KAAK,CATpB;MAcA,IAAMkE,GAAC,GAAGjE,QAAV;;MAMA,IAAIgE,GAAC,IAAI,CAACD,cAAV,EAA0B;QACxBA,cAAc,GAAG,CAAC7F,WAAW,CAAC8F,GAAD,CAAX,GAAiBA,GAAC,CAACxD,KAAnB,GAA2BwD,GAA5B,CAAjB;MACD;;MAOD,IAAIE,eAAJ;;MAEA,IAAMC,UAAQ,GAAG,UACfC,IADe,EAEfpC,IAFe,EAEM;QAErB,OAAO2B,KAAK,CAACC,OAAN,CAAcQ,IAAd,IACF,OAAOpC,IAAP,KAAgB,QAAhB,GAA2BoC,IAAI,CAACpC,IAAD,CAA/B,GAAwC,KAAK,CAD3C,GAEHpC,OAAO,CAACZ,KAAR,CAAcwD,aAAd,CAA4B4B,IAA5B,EAAkCC,MAAM,CAACrC,IAAD,CAAxC,CAFJ;MAGD,CAPD;;MASAvC,SAAS,CAACC,GAAV,CAAc+B,OAAd,CAAsB,UAACS,SAAD,EAAYL,cAAZ,EAA0B;QAC9C,IAAIkC,cAAJ,EAAoB;UAClBA,cAAc,CAAChD,IAAf,CAAoBc,cAApB;QACD;;QACD,IAAMyC,IAAI,GAAGH,UAAQ,CAACH,GAAD,EAAInC,cAAJ,CAArB;QACA,IAAM0C,IAAI,GAAGJ,UAAQ,CAACF,GAAD,EAAIpC,cAAJ,CAArB;;QACA,IAAM2C,IAAI,GAAGnC,KAAI,CAACa,WAAL,CACXhB,SADW,EAEXoC,IAFW,EAGXC,IAHW,EAIX3E,OAJW,EAKXmE,cALW,CAAb;;QAOA,IAAIS,IAAI,KAAKD,IAAb,EAAmB;UACjBL,eAAa,GAAGA,eAAa,IAAI,IAAIvE,GAAJ,EAAjC;UACAuE,eAAa,CAACO,GAAd,CAAkB5C,cAAlB,EAAkC2C,IAAlC;QACD;;QACD,IAAIT,cAAJ,EAAoB;UAClBzG,SAAS,CAACyG,cAAc,CAACW,GAAf,OAAyB7C,cAA1B,CAAT;QACD;MACF,CApBD;;MAsBA,IAAIqC,eAAJ,EAAmB;QAEjBlE,QAAQ,GAAI2D,KAAK,CAACC,OAAN,CAAcK,GAAd,IAAmBA,GAAC,CAACU,KAAF,CAAQ,CAAR,CAAnB,GAA+BC,aAAMX,GAAN,CAA3C;QACAC,eAAa,CAACzC,OAAd,CAAsB,UAACG,KAAD,EAAQI,IAAR,EAAY;UAC/BhC,QAAgB,CAACgC,IAAD,CAAhB,GAAyBJ,KAAzB;QACF,CAFD;MAGD;IACF;;IAED,IAAInC,SAAS,CAACiD,IAAd,EAAoB;MAClB,OAAO,KAAKjE,KAAL,CAAWgC,QAAX,CAAoBoE,gBAApB,CACL9E,QADK,EAELC,QAFK,EAGLP,SAAS,CAACiD,IAHL,EAIL9C,OAJK,EAKLmE,cAAc,IAAI,aAAO,CAAC/E,KAAR,EAAc8F,UAAd,CAAwBC,KAAxB,CAAwBnG,EAAxB,EAA4BmF,cAA5B,CALb,CAAP;IAOD;;IAED,OAAO/D,QAAP;EACD,CA1FO;;EA2FV;AAAC,CA1YD;;;AA4YA,IAAMgF,kBAAkB,GAAgB,EAAxC;;AAEA,SAAS7C,iBAAT,CACEvD,EADF,EAEEoD,IAFF,EAEuB;MADnBtC,GAAG;;EAGL,IAAI,CAACA,GAAG,CAAC2D,GAAJ,CAAQrB,IAAR,CAAL,EAAoB;IAClBtC,GAAG,CAAC+E,GAAJ,CAAQzC,IAAR,EAAcgD,kBAAkB,CAACN,GAAnB,MAA4B;MAAEhF,GAAG,EAAE,IAAIC,GAAJ;IAAP,CAA1C;EACD;;EACD,OAAOD,GAAG,CAAC0B,GAAJ,CAAQY,IAAR,CAAP;AACD;;AAED,SAASW,0BAAT,CACE/D,EADF,EAEEoD,IAFF,EAEuB;MADnBtC,GAAG;EAGL,IAAMwC,SAAS,GAAGxC,GAAG,CAAC0B,GAAJ,CAAQY,IAAR,CAAlB;;EACA,IAAIE,SAAS,IACT,CAACA,SAAS,CAACQ,IADX,IAEA,CAACR,SAAS,CAACxC,GAAV,CAAcuD,IAFnB,EAEyB;IACvB+B,kBAAkB,CAACjE,IAAnB,CAAwBmB,SAAxB;IACAxC,GAAG,CAACuF,MAAJ,CAAWjD,IAAX;EACD;AACF;;AAED,IAAMkD,QAAQ,GAAG,IAAI3D,GAAJ,EAAjB;;AAIA,SAASmC,iBAAT,CACEyB,WADF,EAEEC,WAFF,EAGEvD,cAHF,EAIE7C,KAJF,EAIwB;EAEtB,IAAMqG,QAAQ,GAAG,UAACC,QAAD,EAAkC;IACjD,IAAMC,KAAK,GAAGvG,KAAK,CAACwD,aAAN,CAAiC8C,QAAjC,EAA2CzD,cAA3C,CAAd;IACA,OAAO,OAAO0D,KAAP,KAAiB,QAAjB,IAA6BA,KAApC;EACD,CAHD;;EAKA,IAAMxF,QAAQ,GAAGsF,QAAQ,CAACF,WAAD,CAAzB;EACA,IAAI,CAACpF,QAAL,EAAe;EAEf,IAAMC,QAAQ,GAAGqF,QAAQ,CAACD,WAAD,CAAzB;EACA,IAAI,CAACpF,QAAL,EAAe;EAIf,IAAI9B,WAAW,CAAC6B,QAAD,CAAf,EAA2B;EAI3B,IAAIvC,KAAK,CAACuC,QAAD,EAAWC,QAAX,CAAT,EAA+B;;EAK/B,IAAIV,MAAM,CAACmE,IAAP,CAAY1D,QAAZ,EAAsByF,KAAtB,CACF,eAAG;IAAI,YAAK,CAAChD,aAAN,CAAoBxC,QAApB,EAA8ByF,GAA9B,MAAuC,KAAK,CAA5C;EAA6C,CADlD,CAAJ,EACyD;IACvD;EACD;;EAED,IAAMC,UAAU,GACd1G,KAAK,CAACwD,aAAN,CAA4B2C,WAA5B,EAAyC,YAAzC,KACAnG,KAAK,CAACwD,aAAN,CAA4B4C,WAA5B,EAAyC,YAAzC,CAFF;EAGA,IAAMrD,SAAS,GAAGxD,sBAAsB,CAACsD,cAAD,CAAxC;EACA,IAAM8D,WAAW,GAAMD,UAAU,MAAV,GAAc3D,SAArC;EAEA,IAAImD,QAAQ,CAAC7B,GAAT,CAAasC,WAAb,CAAJ,EAA+B;EAC/BT,QAAQ,CAACnC,GAAT,CAAa4C,WAAb;EAEA,IAAMC,cAAc,GAAa,EAAjC;;EAGA,IAAI,CAACjC,KAAK,CAACC,OAAN,CAAc7D,QAAd,CAAD,IACA,CAAC4D,KAAK,CAACC,OAAN,CAAc5D,QAAd,CADL,EAC8B;IAC5B,CAACD,QAAD,EAAWC,QAAX,EAAqByB,OAArB,CAA6B,iBAAK;MAChC,IAAMP,QAAQ,GAAGlC,KAAK,CAACwD,aAAN,CAAoB+C,KAApB,EAA2B,YAA3B,CAAjB;;MACA,IAAI,OAAOrE,QAAP,KAAoB,QAApB,IACA,CAAC0E,cAAc,CAACC,QAAf,CAAwB3E,QAAxB,CADL,EACwC;QACtC0E,cAAc,CAAC7E,IAAf,CAAoBG,QAApB;MACD;IACF,CAND;EAOD;;EAEDb,YAAUC,QAAV,KACF,YADE,IACFhD,8DAA+EyE,SAA/E,GAA+E,cAA/E,GAA+E2D,UAA/E,GAA+E,6EAA/E,IAGuBE,wBACjB,uCACEA,cAAc,CAACE,IAAf,CAAoB,OAApB,CADF,GACiC,6CAFhB,GAGjB,EANN,IAMQ,yCANR,GAQEH,WARF,GAQa,0EARb,GAWczF,IAAI,CAACC,SAAL,CAAeJ,QAAf,EAAyB4E,KAAzB,CAA+B,CAA/B,EAAkC,IAAlC,CAXd,GAWqD,gBAXrD,GAYczE,IAAI,CAACC,SAAL,CAAeH,QAAf,EAAyB2E,KAAzB,CAA+B,CAA/B,EAAkC,IAAlC,CAZd,GAYqD,gRAZrD,CADE;AAoBD","names":["invariant","InvariantError","equal","createFragmentMap","getFragmentFromSelection","getDefaultValues","getFragmentDefinitions","getOperationDefinition","getTypenameFromResult","makeReference","isField","resultKeyNameFromField","isReference","shouldInclude","hasDirectives","cloneDeep","makeProcessedFieldsMerger","fieldNameFromStoreName","storeValueIsStoreObject","cache","reader","StoreWriter","_a","query","result","dataId","store","variables","operationDefinition","merger","ref","processSelectionSet","Object","create","selectionSet","mergeTree","map","Map","context","written","merge","existing","incoming","varString","JSON","stringify","fragmentMap","process","NODE_ENV","retain","__ref","policies","identify","id","keyObject","sets","indexOf","push","isFresh","incomingFields","typename","rootTypenamesById","get","__typename","workSet","Set","selections","forEach","selection","resultFieldKey","value","storeFieldName","getStoreFieldName","fieldName","name","field","childTree","getChildMergeTree","incomingValue","_this","processFieldValue","childTypename","getFieldValue","getMergeFunction","info","maybeRecycleChildMergeTree","usingPossibleTypes","fragment","fragmentMatches","add","entityRef_1","size","applyMerges","env","hasSelectionSet_1","has","fieldsWithSelectionSets_1","hasMergeFunction_1","Boolean","keys","warnAboutDataLoss","Array","isArray","item","i","getStorageArgs","e_1","i_1","changedFields_1","getValue_1","from","String","eVal","iVal","aVal","set","pop","slice","__assign","runMergeFunction","getStorage","apply","emptyMergeTreePool","delete","warnings","existingRef","incomingObj","getChild","objOrRef","child","every","key","parentType","typeDotName","childTypenames","includes","join"],"sourceRoot":"","sources":["../../../src/cache/inmemory/writeToStore.ts"],"sourcesContent":["import { SelectionSetNode, FieldNode, DocumentNode } from 'graphql';\nimport { invariant, InvariantError } from 'ts-invariant';\nimport { equal } from '@wry/equality';\n\nimport {\n  createFragmentMap,\n  FragmentMap,\n  getFragmentFromSelection,\n  getDefaultValues,\n  getFragmentDefinitions,\n  getOperationDefinition,\n  getTypenameFromResult,\n  makeReference,\n  isField,\n  resultKeyNameFromField,\n  StoreValue,\n  StoreObject,\n  Reference,\n  isReference,\n  shouldInclude,\n  hasDirectives,\n  cloneDeep,\n} from '../../utilities';\n\nimport { NormalizedCache, ReadMergeModifyContext, MergeTree } from './types';\nimport { makeProcessedFieldsMerger, fieldNameFromStoreName, storeValueIsStoreObject } from './helpers';\nimport { StoreReader } from './readFromStore';\nimport { InMemoryCache } from './inMemoryCache';\nimport { EntityStore } from './entityStore';\n\nexport interface WriteContext extends ReadMergeModifyContext {\n  readonly written: {\n    [dataId: string]: SelectionSetNode[];\n  };\n  readonly fragmentMap?: FragmentMap;\n  // General-purpose deep-merge function for use during writes.\n  merge<T>(existing: T, incoming: T): T;\n};\n\ninterface ProcessSelectionSetOptions {\n  dataId?: string,\n  result: Record<string, any>;\n  selectionSet: SelectionSetNode;\n  context: WriteContext;\n  mergeTree: MergeTree;\n}\n\nexport interface WriteToStoreOptions {\n  query: DocumentNode;\n  result: Object;\n  dataId?: string;\n  store: NormalizedCache;\n  variables?: Object;\n}\n\nexport class StoreWriter {\n  constructor(\n    public readonly cache: InMemoryCache,\n    private reader?: StoreReader,\n  ) {}\n\n  /**\n   * Writes the result of a query to the store.\n   *\n   * @param result The result object returned for the query document.\n   *\n   * @param query The query document whose result we are writing to the store.\n   *\n   * @param store The {@link NormalizedCache} used by Apollo for the `data` portion of the store.\n   *\n   * @param variables A map from the name of a variable to its value. These variables can be\n   * referenced by the query document.\n   *\n   * @return A `Reference` to the written object.\n   */\n  public writeToStore({\n    query,\n    result,\n    dataId,\n    store,\n    variables,\n  }: WriteToStoreOptions): Reference | undefined {\n    const operationDefinition = getOperationDefinition(query)!;\n    const merger = makeProcessedFieldsMerger();\n\n    variables = {\n      ...getDefaultValues(operationDefinition),\n      ...variables,\n    };\n\n    const ref = this.processSelectionSet({\n      result: result || Object.create(null),\n      dataId,\n      selectionSet: operationDefinition.selectionSet,\n      mergeTree: { map: new Map },\n      context: {\n        store,\n        written: Object.create(null),\n        merge<T>(existing: T, incoming: T) {\n          return merger.merge(existing, incoming) as T;\n        },\n        variables,\n        varString: JSON.stringify(variables),\n        fragmentMap: createFragmentMap(getFragmentDefinitions(query)),\n      },\n    });\n\n    if (!isReference(ref)) {\n      throw new InvariantError(`Could not identify object ${JSON.stringify(result)}`);\n    }\n\n    // Any IDs written explicitly to the cache will be retained as\n    // reachable root IDs for garbage collection purposes. Although this\n    // logic includes root IDs like ROOT_QUERY and ROOT_MUTATION, their\n    // retainment counts are effectively ignored because cache.gc() always\n    // includes them in its root ID set.\n    store.retain(ref.__ref);\n\n    return ref;\n  }\n\n  private processSelectionSet({\n    dataId,\n    result,\n    selectionSet,\n    context,\n    // This object allows processSelectionSet to report useful information\n    // to its callers without explicitly returning that information.\n    mergeTree,\n  }: ProcessSelectionSetOptions): StoreObject | Reference {\n    const { policies } = this.cache;\n\n    // Identify the result object, even if dataId was already provided,\n    // since we always need keyObject below.\n    const [id, keyObject] = policies.identify(\n      result, selectionSet, context.fragmentMap);\n\n    // If dataId was not provided, fall back to the id just generated by\n    // policies.identify.\n    dataId = dataId || id;\n\n    if (\"string\" === typeof dataId) {\n      // Avoid processing the same entity object using the same selection\n      // set more than once. We use an array instead of a Set since most\n      // entity IDs will be written using only one selection set, so the\n      // size of this array is likely to be very small, meaning indexOf is\n      // likely to be faster than Set.prototype.has.\n      const sets = context.written[dataId] || (context.written[dataId] = []);\n      const ref = makeReference(dataId);\n      if (sets.indexOf(selectionSet) >= 0) return ref;\n      sets.push(selectionSet);\n\n      // If we're about to write a result object into the store, but we\n      // happen to know that the exact same (===) result object would be\n      // returned if we were to reread the result with the same inputs,\n      // then we can skip the rest of the processSelectionSet work for\n      // this object, and immediately return a Reference to it.\n      if (this.reader && this.reader.isFresh(\n        result,\n        ref,\n        selectionSet,\n        context,\n      )) {\n        return ref;\n      }\n    }\n\n    // This variable will be repeatedly updated using context.merge to\n    // accumulate all fields that need to be written into the store.\n    let incomingFields: StoreObject = Object.create(null);\n\n    // Write any key fields that were used during identification, even if\n    // they were not mentioned in the original query.\n    if (keyObject) {\n      incomingFields = context.merge(incomingFields, keyObject);\n    }\n\n    // If typename was not passed in, infer it. Note that typename is\n    // always passed in for tricky-to-infer cases such as \"Query\" for\n    // ROOT_QUERY.\n    const typename =\n      (dataId && policies.rootTypenamesById[dataId]) ||\n      getTypenameFromResult(result, selectionSet, context.fragmentMap) ||\n      (dataId && context.store.get(dataId, \"__typename\") as string);\n\n    if (\"string\" === typeof typename) {\n      incomingFields.__typename = typename;\n    }\n\n    const workSet = new Set(selectionSet.selections);\n\n    workSet.forEach(selection => {\n      if (!shouldInclude(selection, context.variables)) return;\n\n      if (isField(selection)) {\n        const resultFieldKey = resultKeyNameFromField(selection);\n        const value = result[resultFieldKey];\n\n        if (typeof value !== 'undefined') {\n          const storeFieldName = policies.getStoreFieldName({\n            typename,\n            fieldName: selection.name.value,\n            field: selection,\n            variables: context.variables,\n          });\n\n          const childTree = getChildMergeTree(mergeTree, storeFieldName);\n\n          let incomingValue =\n            this.processFieldValue(value, selection, context, childTree);\n\n          const childTypename = selection.selectionSet\n            && context.store.getFieldValue<string>(incomingValue as StoreObject, \"__typename\")\n            || void 0;\n\n          const merge = policies.getMergeFunction(\n            typename,\n            selection.name.value,\n            childTypename,\n          );\n\n          if (merge) {\n            childTree.info = {\n              // TODO Check compatibility against any existing\n              // childTree.field?\n              field: selection,\n              typename,\n              merge,\n            };\n          } else {\n            maybeRecycleChildMergeTree(mergeTree, storeFieldName);\n          }\n\n          incomingFields = context.merge(incomingFields, {\n            [storeFieldName]: incomingValue,\n          });\n\n        } else if (\n          policies.usingPossibleTypes &&\n          !hasDirectives([\"defer\", \"client\"], selection)\n        ) {\n          throw new InvariantError(\n            `Missing field '${resultFieldKey}' in ${JSON.stringify(\n              result,\n              null,\n              2,\n            ).substring(0, 100)}`,\n          );\n        }\n      } else {\n        // This is not a field, so it must be a fragment, either inline or named\n        const fragment = getFragmentFromSelection(\n          selection,\n          context.fragmentMap,\n        );\n\n        if (fragment &&\n            // By passing result and context.variables, we enable\n            // policies.fragmentMatches to bend the rules when typename is\n            // not a known subtype of the fragment type condition, but the\n            // result object contains all the keys requested by the\n            // fragment, which strongly suggests the fragment probably\n            // matched. This fuzzy matching behavior must be enabled by\n            // including a regular expression string (such as \".*\" or\n            // \"Prefix.*\" or \".*Suffix\") in the possibleTypes array for\n            // specific supertypes; otherwise, all matching remains exact.\n            // Fuzzy matches are remembered by the Policies object and\n            // later used when reading from the cache. Since there is no\n            // incoming result object to check when reading, reading does\n            // not involve the same fuzzy inference, so the StoreReader\n            // class calls policies.fragmentMatches without passing result\n            // or context.variables. The flexibility of fuzzy matching\n            // allows existing clients to accommodate previously unknown\n            // __typename strings produced by server/schema changes, which\n            // would otherwise be breaking changes.\n            policies.fragmentMatches(fragment, typename, result, context.variables)) {\n          fragment.selectionSet.selections.forEach(workSet.add, workSet);\n        }\n      }\n    });\n\n    if (\"string\" === typeof dataId) {\n      const entityRef = makeReference(dataId);\n\n      if (mergeTree.map.size) {\n        incomingFields = this.applyMerges(mergeTree, entityRef, incomingFields, context);\n      }\n\n      if (process.env.NODE_ENV !== \"production\") {\n        const hasSelectionSet = (storeFieldName: string) =>\n          fieldsWithSelectionSets.has(fieldNameFromStoreName(storeFieldName));\n        const fieldsWithSelectionSets = new Set<string>();\n        workSet.forEach(selection => {\n          if (isField(selection) && selection.selectionSet) {\n            fieldsWithSelectionSets.add(selection.name.value);\n          }\n        });\n\n        const hasMergeFunction = (storeFieldName: string) => {\n          const childTree = mergeTree.map.get(storeFieldName);\n          return Boolean(childTree && childTree.info && childTree.info.merge);\n        };\n\n        Object.keys(incomingFields).forEach(storeFieldName => {\n          // If a merge function was defined for this field, trust that it\n          // did the right thing about (not) clobbering data. If the field\n          // has no selection set, it's a scalar field, so it doesn't need\n          // a merge function (even if it's an object, like JSON data).\n          if (hasSelectionSet(storeFieldName) &&\n              !hasMergeFunction(storeFieldName)) {\n            warnAboutDataLoss(\n              entityRef,\n              incomingFields,\n              storeFieldName,\n              context.store,\n            );\n          }\n        });\n      }\n\n      context.store.merge(dataId, incomingFields);\n\n      return entityRef;\n    }\n\n    return incomingFields;\n  }\n\n  private processFieldValue(\n    value: any,\n    field: FieldNode,\n    context: WriteContext,\n    mergeTree: MergeTree,\n  ): StoreValue {\n    if (!field.selectionSet || value === null) {\n      // In development, we need to clone scalar values so that they can be\n      // safely frozen with maybeDeepFreeze in readFromStore.ts. In production,\n      // it's cheaper to store the scalar values directly in the cache.\n      return process.env.NODE_ENV === 'production' ? value : cloneDeep(value);\n    }\n\n    if (Array.isArray(value)) {\n      return value.map((item, i) => {\n        const value = this.processFieldValue(\n          item, field, context, getChildMergeTree(mergeTree, i));\n        maybeRecycleChildMergeTree(mergeTree, i);\n        return value;\n      });\n    }\n\n    return this.processSelectionSet({\n      result: value,\n      selectionSet: field.selectionSet,\n      context,\n      mergeTree,\n    });\n  }\n\n  private applyMerges<T extends StoreValue>(\n    mergeTree: MergeTree,\n    existing: StoreValue,\n    incoming: T,\n    context: ReadMergeModifyContext,\n    getStorageArgs?: Parameters<EntityStore[\"getStorage\"]>,\n  ): T {\n    if (mergeTree.map.size && !isReference(incoming)) {\n      const e: StoreObject | Reference | undefined = (\n        // Items in the same position in different arrays are not\n        // necessarily related to each other, so when incoming is an array\n        // we process its elements as if there was no existing data.\n        !Array.isArray(incoming) &&\n        // Likewise, existing must be either a Reference or a StoreObject\n        // in order for its fields to be safe to merge with the fields of\n        // the incoming object.\n        (isReference(existing) || storeValueIsStoreObject(existing))\n      ) ? existing : void 0;\n\n      // This narrowing is implied by mergeTree.map.size > 0 and\n      // !isReference(incoming), though TypeScript understandably cannot\n      // hope to infer this type.\n      const i = incoming as StoreObject | StoreValue[];\n\n      // The options.storage objects provided to read and merge functions\n      // are derived from the identity of the parent object plus a\n      // sequence of storeFieldName strings/numbers identifying the nested\n      // field name path of each field value to be merged.\n      if (e && !getStorageArgs) {\n        getStorageArgs = [isReference(e) ? e.__ref : e];\n      }\n\n      // It's possible that applying merge functions to this subtree will\n      // not change the incoming data, so this variable tracks the fields\n      // that did change, so we can create a new incoming object when (and\n      // only when) at least one incoming field has changed. We use a Map\n      // to preserve the type of numeric keys.\n      let changedFields: Map<string | number, StoreValue> | undefined;\n\n      const getValue = (\n        from: typeof e | typeof i,\n        name: string | number,\n      ): StoreValue => {\n        return Array.isArray(from)\n          ? (typeof name === \"number\" ? from[name] : void 0)\n          : context.store.getFieldValue(from, String(name))\n      };\n\n      mergeTree.map.forEach((childTree, storeFieldName) => {\n        if (getStorageArgs) {\n          getStorageArgs.push(storeFieldName);\n        }\n        const eVal = getValue(e, storeFieldName);\n        const iVal = getValue(i, storeFieldName);\n        const aVal = this.applyMerges(\n          childTree,\n          eVal,\n          iVal,\n          context,\n          getStorageArgs,\n        );\n        if (aVal !== iVal) {\n          changedFields = changedFields || new Map;\n          changedFields.set(storeFieldName, aVal);\n        }\n        if (getStorageArgs) {\n          invariant(getStorageArgs.pop() === storeFieldName);\n        }\n      });\n\n      if (changedFields) {\n        // Shallow clone i so we can add changed fields to it.\n        incoming = (Array.isArray(i) ? i.slice(0) : { ...i }) as T;\n        changedFields.forEach((value, name) => {\n          (incoming as any)[name] = value;\n        });\n      }\n    }\n\n    if (mergeTree.info) {\n      return this.cache.policies.runMergeFunction(\n        existing,\n        incoming,\n        mergeTree.info,\n        context,\n        getStorageArgs && context.store.getStorage(...getStorageArgs),\n      );\n    }\n\n    return incoming;\n  }\n}\n\nconst emptyMergeTreePool: MergeTree[] = [];\n\nfunction getChildMergeTree(\n  { map }: MergeTree,\n  name: string | number,\n): MergeTree {\n  if (!map.has(name)) {\n    map.set(name, emptyMergeTreePool.pop() || { map: new Map });\n  }\n  return map.get(name)!;\n}\n\nfunction maybeRecycleChildMergeTree(\n  { map }: MergeTree,\n  name: string | number,\n) {\n  const childTree = map.get(name);\n  if (childTree &&\n      !childTree.info &&\n      !childTree.map.size) {\n    emptyMergeTreePool.push(childTree);\n    map.delete(name);\n  }\n}\n\nconst warnings = new Set<string>();\n\n// Note that this function is unused in production, and thus should be\n// pruned by any well-configured minifier.\nfunction warnAboutDataLoss(\n  existingRef: Reference,\n  incomingObj: StoreObject,\n  storeFieldName: string,\n  store: NormalizedCache,\n) {\n  const getChild = (objOrRef: StoreObject | Reference): StoreObject | false => {\n    const child = store.getFieldValue<StoreObject>(objOrRef, storeFieldName);\n    return typeof child === \"object\" && child;\n  };\n\n  const existing = getChild(existingRef);\n  if (!existing) return;\n\n  const incoming = getChild(incomingObj);\n  if (!incoming) return;\n\n  // It's always safe to replace a reference, since it refers to data\n  // safely stored elsewhere.\n  if (isReference(existing)) return;\n\n  // If the values are structurally equivalent, we do not need to worry\n  // about incoming replacing existing.\n  if (equal(existing, incoming)) return;\n\n  // If we're replacing every key of the existing object, then the\n  // existing data would be overwritten even if the objects were\n  // normalized, so warning would not be helpful here.\n  if (Object.keys(existing).every(\n    key => store.getFieldValue(incoming, key) !== void 0)) {\n    return;\n  }\n\n  const parentType =\n    store.getFieldValue<string>(existingRef, \"__typename\") ||\n    store.getFieldValue<string>(incomingObj, \"__typename\");\n  const fieldName = fieldNameFromStoreName(storeFieldName);\n  const typeDotName = `${parentType}.${fieldName}`;\n  // Avoid warning more than once for the same type and field name.\n  if (warnings.has(typeDotName)) return;\n  warnings.add(typeDotName);\n\n  const childTypenames: string[] = [];\n  // Arrays do not have __typename fields, and always need a custom merge\n  // function, even if their elements are normalized entities.\n  if (!Array.isArray(existing) &&\n      !Array.isArray(incoming)) {\n    [existing, incoming].forEach(child => {\n      const typename = store.getFieldValue(child, \"__typename\");\n      if (typeof typename === \"string\" &&\n          !childTypenames.includes(typename)) {\n        childTypenames.push(typename);\n      }\n    });\n  }\n\n  invariant.warn(\n`Cache data may be lost when replacing the ${fieldName} field of a ${parentType} object.\n\nTo address this problem (which is not a bug in Apollo Client), ${\n  childTypenames.length\n    ? \"either ensure all objects of type \" +\n        childTypenames.join(\" and \") + \" have an ID or a custom merge function, or \"\n    : \"\"\n}define a custom merge function for the ${\n  typeDotName\n} field, so InMemoryCache can safely merge these objects:\n\n  existing: ${JSON.stringify(existing).slice(0, 1000)}\n  incoming: ${JSON.stringify(incoming).slice(0, 1000)}\n\nFor more information about these options, please refer to the documentation:\n\n  * Ensuring entity objects have IDs: https://go.apollo.dev/c/generating-unique-identifiers\n  * Defining custom merge functions: https://go.apollo.dev/c/merging-non-normalized-objects\n`);\n}\n"]},"metadata":{},"sourceType":"module"}